{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6c74343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as patches\n",
    "import glob\n",
    "import os\n",
    "from config_utility import *\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc41135c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done collected: 3009\n",
      "3009\n"
     ]
    }
   ],
   "source": [
    "xy_norm = lambda x: (x)/160000\n",
    "z_norm = lambda x: (x-2000)/2000\n",
    "p_norm = lambda x: (x)/172\n",
    "t_norm = lambda x: (x)/70\n",
    "k_norm = lambda x: (x)/100\n",
    "\n",
    "times = np.cumsum(10*np.array(np.power(1.2531,np.arange(1,25,1)), dtype=int))\n",
    "times = times/ 10950\n",
    "\n",
    "PT_GLOBAL_PATH = f'../dataset/dP_GLOBAL/'\n",
    "pt_files = os.listdir(PT_GLOBAL_PATH)\n",
    "print('done collected:', len(pt_files))\n",
    "\n",
    "GLOBAL_names = []\n",
    "for file in pt_files:\n",
    "    l = file.split('_')\n",
    "    GLOBAL_names.append((f'{l[0]}_{l[1]}', int(l[2])))\n",
    "print(len(GLOBAL_names))\n",
    "\n",
    "# find reservoirs that has not been collected\n",
    "path = f'../dataset/SG_LGR4/'\n",
    "if not os.path.exists(path):\n",
    "    os.mkdir(path)\n",
    "files = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a689102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3098"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"PERF_DICT.json\",\"r\")\n",
    "PERF_DICT = json.load(f)\n",
    "f.close()\n",
    "perf_names = list(PERF_DICT.keys())\n",
    "len(perf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a51969c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "files.remove('.ipynb_checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fbfaf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3009\n"
     ]
    }
   ],
   "source": [
    "collected_names = []\n",
    "for file in files:\n",
    "    l = file.split('_')\n",
    "    collected_names.append((f'{l[0]}_{l[1]}', int(l[2])))\n",
    "print(len(collected_names))\n",
    "\n",
    "to_load_names = []\n",
    "for elem in GLOBAL_names:\n",
    "    if elem not in collected_names:\n",
    "        to_load_names.append(elem)\n",
    "        \n",
    "print(len(to_load_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d812e175",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('slope_3', 6)\n"
     ]
    }
   ],
   "source": [
    "NX, NY, NZ, NT = 40, 40, 50, 24\n",
    "ROOT_PATH = '../..'\n",
    "\n",
    "for names in to_load_names:\n",
    "    try:\n",
    "        slope_name, idx = names\n",
    "        case_name = f'case_{idx}'\n",
    "        meta_data = np.load(f'{ROOT_PATH}/ECLIPSE/meta_data/{slope_name}_{idx}.npy', allow_pickle=True).tolist()\n",
    "\n",
    "        for k, v in meta_data[case_name].items():\n",
    "            globals()[k]=v\n",
    "\n",
    "        OUTPUT_DICT = return_OUTPUT_DICT(meta_data, case_name)\n",
    "\n",
    "        p, t, rate = INPUT_DICT['p'], INPUT_DICT['temp'], INPUT_DICT['inj']\n",
    "        INJ_MAP_DICT = return_inj_map_dict(WELL_LIST,rate,INJ_LOCATION_DICT,GRID_CENTER_DICT, LGR_LIST)\n",
    "\n",
    "        for well in WELL_LIST:\n",
    "            gridx = np.repeat(xy_norm(GRID_CENTER_DICT[well]['LGR4']['grid_x'])[...,None,None], 24, axis=-2)\n",
    "            gridy = np.repeat(xy_norm(GRID_CENTER_DICT[well]['LGR4']['grid_y'])[...,None,None], 24, axis=-2)\n",
    "            gridz = np.repeat(z_norm(TOPS_DICT[well]['LGR4'][0,...,None,None]), 24, axis=-2)\n",
    "            gridt = (np.ones(gridz.shape)* times[None,None,None,:,None])\n",
    "\n",
    "            inj = np.repeat(INJ_MAP_DICT[well]['LGR4'][...,None,None], 24, axis=-2)\n",
    "            pressure = np.repeat(p_norm(return_upsample_dict(OUTPUT_DICT, 0, 'BPR', \n",
    "                                                   WELL_LIST, GRID_IDX_DICT)[well]['LGR4'][0,...,None,None]), 24, axis=-2)\n",
    "            temp = t_norm(t) * np.ones(inj.shape)\n",
    "            perm = np.repeat(k_norm(PERM_DICT[well]['LGR4'])[0,...,None,None], 24, axis=-2)\n",
    "\n",
    "\n",
    "            DICT = return_upsample_all_time(OUTPUT_DICT, 'BGSAT', WELL_LIST, GRID_IDX_DICT, LGR_LIST)\n",
    "\n",
    "            coarse = DICT[well]['LGR3'][0,:,:,:,:,None]\n",
    "            x_DP = np.concatenate([gridx, gridy, gridz, gridt, inj, pressure, temp, perm, coarse], axis=-1)[None,...]\n",
    "            y_DP = DICT[well]['LGR4'][...,None]\n",
    "\n",
    "            x_DP = torch.from_numpy(x_DP.astype(np.float32))\n",
    "            y_DP = torch.from_numpy(y_DP.astype(np.float32))\n",
    "\n",
    "            perf = PERF_DICT[f'{slope_name}_{idx}'][f'INJ{well[-1]}']\n",
    "            old_inj = torch.clone(x_DP[0,19,19,:,:,4])\n",
    "            new_inj = torch.zeros(old_inj.shape)\n",
    "            new_inj[perf[0]-1:perf[1],:] = old_inj[perf[0]-1:perf[1],:]\n",
    "            x_DP[0,19,19,:,:,4] = new_inj\n",
    "\n",
    "            data = {}\n",
    "            data['input'] = x_DP\n",
    "            data['output'] = y_DP\n",
    "            torch.save(data, f'../dataset/SG_LGR4/{slope_name}_{idx}_LGR4_{well}_SG.pt')\n",
    "    except:\n",
    "        print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9c84b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3098"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "f = open(\"PERF_DICT_v2.json\",\"r\")\n",
    "PERF_DICT = json.load(f)\n",
    "f.close()\n",
    "perf_names = list(PERF_DICT.keys())\n",
    "len(perf_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "635b53b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'INJ1': [31, 50], 'INJ2': [1, 40], 'INJ3': [1, 20], 'INJ4': [11, 20]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PERF_DICT['slope_3_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032259ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
